# hybrid-llm-inference/configs/hardware_config.yaml
m1_pro:
  device_type: cpu_gpu
  device_id: 0
  idle_power: 10.0
  sample_interval: 0.1
a100:
  device_type: gpu
  device_id: 0
  idle_power: 40.0
  sample_interval: 200
rtx4050:
  device_type: gpu
  device_id: 1
  idle_power: 15.0
  sample_interval: 200
a800:
  device_type: gpu
  device_id: 2
  idle_power: 50.0
  sample_interval: 200
